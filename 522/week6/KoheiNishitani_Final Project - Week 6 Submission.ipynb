{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88bcaec-3e53-4930-8ec5-3cdb05745515",
   "metadata": {},
   "source": [
    "# Final Project - Week 6 Submission\n",
    "### Data Analysis\n",
    "### Due: Tuesday, December 3, 2024 at 11:59 PM\n",
    "\n",
    "Building upon your Week 5 cleaned dataset, this week focuses on conducting data analysis of your **cleaned dataset** to uncover patterns, relationships, and key insights that address your research questions. \n",
    "\n",
    "#### Submission Requirements:\n",
    "- Submit a PDF or Jupyter notebook (.ipynb) containing:\n",
    "  - All code with outputs visible\n",
    "  - Clear documentation for data analysis (Part 4)\n",
    "    - You can use markdown in Jupyter notebook, or write your final summary in Word/PDF. If you choose Word/PDF, please still submit your notebook/PDF containing the code)<br><br>\n",
    "\n",
    "    \n",
    "  \n",
    "- For individual submission: Include your name in either the filename or within the notebook content\n",
    "- For team submission: \n",
    "  1. Include all team members' names in the notebook content\n",
    "  2. For team members from different sessions, clearly indicate their session numbers\n",
    "  3. All team members are required to submit a copy of the assignment\n",
    "\n",
    ">**Note**: I provide some example codes for some data analysis tasks. Feel free to modify these codes to fit your specific dataset and research questions, or you can write your own code that better suits your analysis needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b59645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('/Users/nkohei/Workspace/McDaniel-Repository/522/final project')\n",
    "os.getcwd()\n",
    "\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "df['all_tooth_exist'] = np.where(\n",
    "    (df['num_incisors'] == 4) & \n",
    "    (df['num_canines'] == 2) & \n",
    "    (df['num_premolars'] == 4) & \n",
    "    (df['num_molars'] == 4), \n",
    "    'all_detected', \n",
    "    'missing_or_extracted'\n",
    ")\n",
    "\n",
    "df['arch_discrepancy_severity'] = pd.cut(\n",
    "    df['arch_length_discrepancy'],  # Column to categorize\n",
    "    bins=4,  # Number of equal-width bins\n",
    "    labels=['low', 'medium', 'high', 'very_high']  # Custom labels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49a0c0-24c1-40dd-9713-337eb6644240",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d757ec-dbb8-4202-8fc6-12e431861915",
   "metadata": {},
   "source": [
    "## Part 1: Descriptive Statistics\n",
    "Using your cleaned dataset from the previous week, conduct a comprehensive descriptive statistical analysis to summarize the key characteristics of the data.\n",
    ">**Note**: If you have already completed this analysis in a previous step, there is no need to repeat it. However, if your cleaned dataset differs from the dataset before cleaning, please use your final dataset for this part to identify any new findings or insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb619a2-7fb7-479f-982d-0fcda4d3fc63",
   "metadata": {},
   "source": [
    "1. **Central Tendency**\n",
    "\n",
    "- Measures like mean, median, and mode\n",
    "  - *Purpose*: Reveals the typical or representative values in your variables, helping identify patterns and trends relevant to your research questions. For example, if studying house prices, these measures indicate whether average house prices in one area are higher than others, offering insights into housing market dynamics and regional differences.\n",
    "\n",
    "2. **Dispersion**\n",
    "\n",
    "- Measures like standard deviation, variance, range, and IQR (Interquartile Range)\n",
    "  - *Purpose*: Shows data variability and distribution shape, helping identify significant variations in your key variables. For example, high dispersion in test scores might indicate educational inequality, while low dispersion in prices might suggest market stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d97e02-1e47-403a-b8de-7ffa5776ef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detected_arch_length</th>\n",
       "      <th>simulated_arch_length</th>\n",
       "      <th>arch_length_discrepancy</th>\n",
       "      <th>num_incisors</th>\n",
       "      <th>num_canines</th>\n",
       "      <th>num_premolars</th>\n",
       "      <th>num_molars</th>\n",
       "      <th>avg_confidence_incisor</th>\n",
       "      <th>avg_confidence_canine</th>\n",
       "      <th>avg_confidence_premolar</th>\n",
       "      <th>avg_confidence_molar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2012.522671</td>\n",
       "      <td>1910.301280</td>\n",
       "      <td>102.221391</td>\n",
       "      <td>4.007507</td>\n",
       "      <td>2.000609</td>\n",
       "      <td>3.935890</td>\n",
       "      <td>4.342057</td>\n",
       "      <td>0.890299</td>\n",
       "      <td>0.892062</td>\n",
       "      <td>0.894154</td>\n",
       "      <td>0.902066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>125.853247</td>\n",
       "      <td>118.478953</td>\n",
       "      <td>79.634064</td>\n",
       "      <td>0.178332</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.373031</td>\n",
       "      <td>0.735699</td>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>0.021852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1500.511894</td>\n",
       "      <td>1181.883742</td>\n",
       "      <td>-340.887450</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.682740</td>\n",
       "      <td>0.612709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1935.920903</td>\n",
       "      <td>1841.472148</td>\n",
       "      <td>60.088269</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.889150</td>\n",
       "      <td>0.890490</td>\n",
       "      <td>0.893100</td>\n",
       "      <td>0.902140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.437658</td>\n",
       "      <td>1912.985490</td>\n",
       "      <td>87.406464</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.892354</td>\n",
       "      <td>0.895022</td>\n",
       "      <td>0.897191</td>\n",
       "      <td>0.907191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2088.885411</td>\n",
       "      <td>1979.329743</td>\n",
       "      <td>121.486154</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.895338</td>\n",
       "      <td>0.899111</td>\n",
       "      <td>0.901130</td>\n",
       "      <td>0.911424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2546.803910</td>\n",
       "      <td>2449.704441</td>\n",
       "      <td>1204.224423</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.908154</td>\n",
       "      <td>0.917876</td>\n",
       "      <td>0.925435</td>\n",
       "      <td>0.931001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       detected_arch_length  simulated_arch_length  arch_length_discrepancy  \\\n",
       "count           4929.000000            4929.000000              4929.000000   \n",
       "mean            2012.522671            1910.301280               102.221391   \n",
       "std              125.853247             118.478953                79.634064   \n",
       "min             1500.511894            1181.883742              -340.887450   \n",
       "25%             1935.920903            1841.472148                60.088269   \n",
       "50%             2011.437658            1912.985490                87.406464   \n",
       "75%             2088.885411            1979.329743               121.486154   \n",
       "max             2546.803910            2449.704441              1204.224423   \n",
       "\n",
       "       num_incisors  num_canines  num_premolars   num_molars  \\\n",
       "count   4929.000000  4929.000000    4929.000000  4929.000000   \n",
       "mean       4.007507     2.000609       3.935890     4.342057   \n",
       "std        0.178332     0.084273       0.373031     0.735699   \n",
       "min        2.000000     0.000000       2.000000     1.000000   \n",
       "25%        4.000000     2.000000       4.000000     4.000000   \n",
       "50%        4.000000     2.000000       4.000000     4.000000   \n",
       "75%        4.000000     2.000000       4.000000     5.000000   \n",
       "max        6.000000     3.000000       7.000000     7.000000   \n",
       "\n",
       "       avg_confidence_incisor  avg_confidence_canine  avg_confidence_premolar  \\\n",
       "count             4929.000000            4929.000000              4929.000000   \n",
       "mean                 0.890299               0.892062                 0.894154   \n",
       "std                  0.013824               0.026383                 0.019228   \n",
       "min                  0.737696               0.000000                 0.682740   \n",
       "25%                  0.889150               0.890490                 0.893100   \n",
       "50%                  0.892354               0.895022                 0.897191   \n",
       "75%                  0.895338               0.899111                 0.901130   \n",
       "max                  0.908154               0.917876                 0.925435   \n",
       "\n",
       "       avg_confidence_molar  \n",
       "count           4929.000000  \n",
       "mean               0.902066  \n",
       "std                0.021852  \n",
       "min                0.612709  \n",
       "25%                0.902140  \n",
       "50%                0.907191  \n",
       "75%                0.911424  \n",
       "max                0.931001  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022a8b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detected_arch_length</th>\n",
       "      <th>simulated_arch_length</th>\n",
       "      <th>arch_length_discrepancy</th>\n",
       "      <th>num_incisors</th>\n",
       "      <th>num_canines</th>\n",
       "      <th>num_premolars</th>\n",
       "      <th>num_molars</th>\n",
       "      <th>avg_confidence_incisor</th>\n",
       "      <th>avg_confidence_canine</th>\n",
       "      <th>avg_confidence_premolar</th>\n",
       "      <th>avg_confidence_molar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>15839.039705</td>\n",
       "      <td>14037.262368</td>\n",
       "      <td>6341.584173</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>0.139152</td>\n",
       "      <td>0.541252</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>125.853247</td>\n",
       "      <td>118.478953</td>\n",
       "      <td>79.634064</td>\n",
       "      <td>0.178332</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.373031</td>\n",
       "      <td>0.735699</td>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>0.021852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculate_range</th>\n",
       "      <td>1046.292016</td>\n",
       "      <td>1267.820699</td>\n",
       "      <td>1545.111873</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.170458</td>\n",
       "      <td>0.917876</td>\n",
       "      <td>0.242695</td>\n",
       "      <td>0.318292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculate_iqr</th>\n",
       "      <td>152.964508</td>\n",
       "      <td>137.857595</td>\n",
       "      <td>61.397885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.008030</td>\n",
       "      <td>0.009284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 detected_arch_length  simulated_arch_length  \\\n",
       "var                      15839.039705           14037.262368   \n",
       "std                        125.853247             118.478953   \n",
       "calculate_range           1046.292016            1267.820699   \n",
       "calculate_iqr              152.964508             137.857595   \n",
       "\n",
       "                 arch_length_discrepancy  num_incisors  num_canines  \\\n",
       "var                          6341.584173      0.031802     0.007102   \n",
       "std                            79.634064      0.178332     0.084273   \n",
       "calculate_range              1545.111873      4.000000     3.000000   \n",
       "calculate_iqr                  61.397885      0.000000     0.000000   \n",
       "\n",
       "                 num_premolars  num_molars  avg_confidence_incisor  \\\n",
       "var                   0.139152    0.541252                0.000191   \n",
       "std                   0.373031    0.735699                0.013824   \n",
       "calculate_range       5.000000    6.000000                0.170458   \n",
       "calculate_iqr         0.000000    1.000000                0.006188   \n",
       "\n",
       "                 avg_confidence_canine  avg_confidence_premolar  \\\n",
       "var                           0.000696                 0.000370   \n",
       "std                           0.026383                 0.019228   \n",
       "calculate_range               0.917876                 0.242695   \n",
       "calculate_iqr                 0.008621                 0.008030   \n",
       "\n",
       "                 avg_confidence_molar  \n",
       "var                          0.000477  \n",
       "std                          0.021852  \n",
       "calculate_range              0.318292  \n",
       "calculate_iqr                0.009284  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_range(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "def calculate_iqr(series):\n",
    "    return series.quantile(0.75) - series.quantile(0.25)\n",
    "\n",
    "numeric_columns = df.select_dtypes(include='number')\n",
    "\n",
    "aggregation_results = numeric_columns.agg(['var', 'std', calculate_range, calculate_iqr])\n",
    "aggregation_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f6cb1-63ca-4759-8c88-d26b2af05179",
   "metadata": {},
   "source": [
    "1. Central Tendency\n",
    "- Mean aggregation: Detected_arch_length has longer than simulated_arch_length. Given Orthodontics potential patients, this discrepancy is expected\n",
    "- Min aggregation: Given negative value at arch_length_discrepancy, some patient has much shorter detected_arch_length.\n",
    "\n",
    "\n",
    "2. Dispersion\n",
    "- Std: Because arch simulation method employs smoothed curve fitting, it has less standard deviation than detected arch length.\n",
    "- Range x IQR : detected arch length has longer IQR than simulated_arch_length, but not same result from Range. It may indicate the some outliner still exist in either length value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340343",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a618e47-67fd-4eeb-b704-99d0a4fcf2c2",
   "metadata": {},
   "source": [
    "2. **Categorical Analysis**\n",
    "   \n",
    "For categorical variables:\n",
    "\n",
    "- Calculate and interpret frequency distributions <br><br>\n",
    "- If applicable and needed, create cross-tabulations for relevant variable pairs\n",
    "     - Purpose: Displays the interaction between two categorical variables, helping to uncover relationships between categories.\n",
    "     - Example: Analyzing a cross-tabulation of gender and product purchase might show that females are more likely to purchase a particular product than males, providing valuable input for marketing strategies.<br><br>\n",
    "- If applicable and needed, conduct Chi-square tests of independence.\n",
    "     - Purpose: Tests whether there is a statistically significant association between two categorical variables.\n",
    "     - Example: For instance, a Chi-square test might reveal that gender significantly impacts customer feedback preferences (p-value < 0.05), offering key insights for customer segmentation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1876d4c-4978-42a1-aa46-d67afd091bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "basic          3168\n",
      "pro             624\n",
      "regrettable     569\n",
      "invisalign      568\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "basic          0.642727\n",
      "pro            0.126598\n",
      "regrettable    0.115439\n",
      "invisalign     0.115236\n",
      "Name: proportion, dtype: float64\n",
      "---\n",
      "Chi-square test statistic: 44.997469089591235\n",
      "p-value: 9.264168738865696e-10\n",
      "Degrees of freedom: 3\n",
      "Expected frequencies:\n",
      "[[2084.36275107 1083.63724893]\n",
      " [ 373.71150335  194.28849665]\n",
      " [ 410.55629945  213.44370055]\n",
      " [ 374.36944614  194.63055386]]\n"
     ]
    }
   ],
   "source": [
    "# Example code for categorical analysis\n",
    "# Analyze relationship between employee gender and department distribution\n",
    "\n",
    "# Frequency analysis\n",
    "print(df['label'].value_counts())\n",
    "print(df['label'].value_counts(normalize=True))\n",
    "\n",
    "# Cross-tabulation analysis\n",
    "dept_gender_tab = pd.crosstab(\n",
    "   df['label'],\n",
    "   df['all_tooth_exist'],\n",
    "   margins=True\n",
    ")\n",
    "\n",
    "# Chi-square test\n",
    "from scipy.stats import chi2_contingency\n",
    "contingency_table = pd.crosstab(df['label'], df['all_tooth_exist'])\n",
    "\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"---\")\n",
    "print(f'Chi-square test statistic: {chi2}')\n",
    "print(f'p-value: {p_value}')\n",
    "print(f'Degrees of freedom: {dof}')\n",
    "print('Expected frequencies:')\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4c9a0-0720-460f-8c7f-486115a496b1",
   "metadata": {},
   "source": [
    ">**Optional**: If your dataset is suitable, we can also practice the Data Wrangling concepts we learned this week. Below are some general examples, but please adapt these codes according to your dataset or practice with other codes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459f715d-448c-4ee9-9548-3e3e40e95e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>detected_arch_length</th>\n",
       "      <th>simulated_arch_length</th>\n",
       "      <th>arch_length_discrepancy</th>\n",
       "      <th>num_incisors</th>\n",
       "      <th>num_canines</th>\n",
       "      <th>num_premolars</th>\n",
       "      <th>num_molars</th>\n",
       "      <th>avg_confidence_incisor</th>\n",
       "      <th>avg_confidence_canine</th>\n",
       "      <th>avg_confidence_premolar</th>\n",
       "      <th>avg_confidence_molar</th>\n",
       "      <th>detected_arch_length_outliers_flg</th>\n",
       "      <th>arch_discrepancy_severity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>all_tooth_exist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">basic</th>\n",
       "      <th>all_detected</th>\n",
       "      <td>1885.302329</td>\n",
       "      <td>1816.008383</td>\n",
       "      <td>69.293946</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887684</td>\n",
       "      <td>0.894043</td>\n",
       "      <td>0.906347</td>\n",
       "      <td>0.913622</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_detected</th>\n",
       "      <td>1971.601911</td>\n",
       "      <td>1948.123640</td>\n",
       "      <td>23.478271</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.895110</td>\n",
       "      <td>0.900412</td>\n",
       "      <td>0.900419</td>\n",
       "      <td>0.907105</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_detected</th>\n",
       "      <td>1682.730307</td>\n",
       "      <td>1660.049287</td>\n",
       "      <td>22.681020</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.890298</td>\n",
       "      <td>0.895315</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_detected</th>\n",
       "      <td>1889.994699</td>\n",
       "      <td>1797.104997</td>\n",
       "      <td>92.889702</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>0.892443</td>\n",
       "      <td>0.885249</td>\n",
       "      <td>0.908655</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_detected</th>\n",
       "      <td>1803.870817</td>\n",
       "      <td>1720.724704</td>\n",
       "      <td>83.146113</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891748</td>\n",
       "      <td>0.898954</td>\n",
       "      <td>0.898250</td>\n",
       "      <td>0.913284</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">regrettable</th>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>1885.352280</td>\n",
       "      <td>1792.052169</td>\n",
       "      <td>93.300111</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.889672</td>\n",
       "      <td>0.899963</td>\n",
       "      <td>0.894997</td>\n",
       "      <td>0.914774</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>1876.981307</td>\n",
       "      <td>1787.897487</td>\n",
       "      <td>89.083820</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873379</td>\n",
       "      <td>0.884697</td>\n",
       "      <td>0.899809</td>\n",
       "      <td>0.908093</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>2365.197006</td>\n",
       "      <td>2218.604058</td>\n",
       "      <td>146.592947</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.879106</td>\n",
       "      <td>0.892412</td>\n",
       "      <td>0.885477</td>\n",
       "      <td>0.826385</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>2382.072374</td>\n",
       "      <td>2187.436244</td>\n",
       "      <td>194.636130</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.887715</td>\n",
       "      <td>0.893488</td>\n",
       "      <td>0.895949</td>\n",
       "      <td>0.893946</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>1895.140648</td>\n",
       "      <td>1816.560514</td>\n",
       "      <td>78.580133</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.897105</td>\n",
       "      <td>0.896997</td>\n",
       "      <td>0.892253</td>\n",
       "      <td>0.908239</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4929 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  detected_arch_length  simulated_arch_length  \\\n",
       "label       all_tooth_exist                                                     \n",
       "basic       all_detected                   1885.302329            1816.008383   \n",
       "            all_detected                   1971.601911            1948.123640   \n",
       "            all_detected                   1682.730307            1660.049287   \n",
       "            all_detected                   1889.994699            1797.104997   \n",
       "            all_detected                   1803.870817            1720.724704   \n",
       "...                                                ...                    ...   \n",
       "regrettable missing_or_extracted           1885.352280            1792.052169   \n",
       "            missing_or_extracted           1876.981307            1787.897487   \n",
       "            missing_or_extracted           2365.197006            2218.604058   \n",
       "            missing_or_extracted           2382.072374            2187.436244   \n",
       "            missing_or_extracted           1895.140648            1816.560514   \n",
       "\n",
       "                                  arch_length_discrepancy  num_incisors  \\\n",
       "label       all_tooth_exist                                               \n",
       "basic       all_detected                        69.293946             4   \n",
       "            all_detected                        23.478271             4   \n",
       "            all_detected                        22.681020             4   \n",
       "            all_detected                        92.889702             4   \n",
       "            all_detected                        83.146113             4   \n",
       "...                                                   ...           ...   \n",
       "regrettable missing_or_extracted                93.300111             3   \n",
       "            missing_or_extracted                89.083820             4   \n",
       "            missing_or_extracted               146.592947             5   \n",
       "            missing_or_extracted               194.636130             4   \n",
       "            missing_or_extracted                78.580133             4   \n",
       "\n",
       "                                  num_canines  num_premolars  num_molars  \\\n",
       "label       all_tooth_exist                                                \n",
       "basic       all_detected                    2              4           4   \n",
       "            all_detected                    2              4           4   \n",
       "            all_detected                    2              4           4   \n",
       "            all_detected                    2              4           4   \n",
       "            all_detected                    2              4           4   \n",
       "...                                       ...            ...         ...   \n",
       "regrettable missing_or_extracted            2              4           4   \n",
       "            missing_or_extracted            2              4           3   \n",
       "            missing_or_extracted            2              4           6   \n",
       "            missing_or_extracted            2              4           6   \n",
       "            missing_or_extracted            2              4           5   \n",
       "\n",
       "                                  avg_confidence_incisor  \\\n",
       "label       all_tooth_exist                                \n",
       "basic       all_detected                        0.887684   \n",
       "            all_detected                        0.895110   \n",
       "            all_detected                        0.894340   \n",
       "            all_detected                        0.894349   \n",
       "            all_detected                        0.891748   \n",
       "...                                                  ...   \n",
       "regrettable missing_or_extracted                0.889672   \n",
       "            missing_or_extracted                0.873379   \n",
       "            missing_or_extracted                0.879106   \n",
       "            missing_or_extracted                0.887715   \n",
       "            missing_or_extracted                0.897105   \n",
       "\n",
       "                                  avg_confidence_canine  \\\n",
       "label       all_tooth_exist                               \n",
       "basic       all_detected                       0.894043   \n",
       "            all_detected                       0.900412   \n",
       "            all_detected                       0.890298   \n",
       "            all_detected                       0.892443   \n",
       "            all_detected                       0.898954   \n",
       "...                                                 ...   \n",
       "regrettable missing_or_extracted               0.899963   \n",
       "            missing_or_extracted               0.884697   \n",
       "            missing_or_extracted               0.892412   \n",
       "            missing_or_extracted               0.893488   \n",
       "            missing_or_extracted               0.896997   \n",
       "\n",
       "                                  avg_confidence_premolar  \\\n",
       "label       all_tooth_exist                                 \n",
       "basic       all_detected                         0.906347   \n",
       "            all_detected                         0.900419   \n",
       "            all_detected                         0.895315   \n",
       "            all_detected                         0.885249   \n",
       "            all_detected                         0.898250   \n",
       "...                                                   ...   \n",
       "regrettable missing_or_extracted                 0.894997   \n",
       "            missing_or_extracted                 0.899809   \n",
       "            missing_or_extracted                 0.885477   \n",
       "            missing_or_extracted                 0.895949   \n",
       "            missing_or_extracted                 0.892253   \n",
       "\n",
       "                                  avg_confidence_molar  \\\n",
       "label       all_tooth_exist                              \n",
       "basic       all_detected                      0.913622   \n",
       "            all_detected                      0.907105   \n",
       "            all_detected                      0.914344   \n",
       "            all_detected                      0.908655   \n",
       "            all_detected                      0.913284   \n",
       "...                                                ...   \n",
       "regrettable missing_or_extracted              0.914774   \n",
       "            missing_or_extracted              0.908093   \n",
       "            missing_or_extracted              0.826385   \n",
       "            missing_or_extracted              0.893946   \n",
       "            missing_or_extracted              0.908239   \n",
       "\n",
       "                                  detected_arch_length_outliers_flg  \\\n",
       "label       all_tooth_exist                                           \n",
       "basic       all_detected                                      False   \n",
       "            all_detected                                      False   \n",
       "            all_detected                                      False   \n",
       "            all_detected                                      False   \n",
       "            all_detected                                      False   \n",
       "...                                                             ...   \n",
       "regrettable missing_or_extracted                              False   \n",
       "            missing_or_extracted                              False   \n",
       "            missing_or_extracted                              False   \n",
       "            missing_or_extracted                              False   \n",
       "            missing_or_extracted                              False   \n",
       "\n",
       "                                 arch_discrepancy_severity  \n",
       "label       all_tooth_exist                                 \n",
       "basic       all_detected                            medium  \n",
       "            all_detected                               low  \n",
       "            all_detected                               low  \n",
       "            all_detected                            medium  \n",
       "            all_detected                            medium  \n",
       "...                                                    ...  \n",
       "regrettable missing_or_extracted                    medium  \n",
       "            missing_or_extracted                    medium  \n",
       "            missing_or_extracted                    medium  \n",
       "            missing_or_extracted                    medium  \n",
       "            missing_or_extracted                    medium  \n",
       "\n",
       "[4929 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: Multi-level indexing\n",
    "df_multi = df.set_index(\n",
    "    ['label', 'all_tooth_exist']\n",
    ").sort_index()\n",
    "\n",
    "# Example 2: Index names setting\n",
    "df_multi.index.names = ['label', 'all_tooth_exist']\n",
    "\n",
    "df_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcb9695-9260-446a-b3be-10c11b690ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/jzgwrdks2vq53w20jlljrk840000gn/T/ipykernel_81286/659605350.py:2: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  pivot_result = pd.pivot_table(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch_discrepancy_severity</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>high</th>\n",
       "      <th>very_high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>all_tooth_exist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">basic</th>\n",
       "      <th>all_detected</th>\n",
       "      <td>1907.529430</td>\n",
       "      <td>1896.107729</td>\n",
       "      <td>1567.233475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>1973.022381</td>\n",
       "      <td>1939.921014</td>\n",
       "      <td>1723.179717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">invisalign</th>\n",
       "      <th>all_detected</th>\n",
       "      <td>1943.234279</td>\n",
       "      <td>1893.780442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>2009.875878</td>\n",
       "      <td>1960.830164</td>\n",
       "      <td>1550.431395</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pro</th>\n",
       "      <th>all_detected</th>\n",
       "      <td>1907.113823</td>\n",
       "      <td>1897.033699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>2030.177174</td>\n",
       "      <td>1936.812662</td>\n",
       "      <td>1714.977095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">regrettable</th>\n",
       "      <th>all_detected</th>\n",
       "      <td>1913.685486</td>\n",
       "      <td>1875.341052</td>\n",
       "      <td>1688.800034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_or_extracted</th>\n",
       "      <td>1961.329248</td>\n",
       "      <td>1898.286401</td>\n",
       "      <td>1729.345967</td>\n",
       "      <td>1286.472635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "arch_discrepancy_severity                 low       medium         high  \\\n",
       "label       all_tooth_exist                                               \n",
       "basic       all_detected          1907.529430  1896.107729  1567.233475   \n",
       "            missing_or_extracted  1973.022381  1939.921014  1723.179717   \n",
       "invisalign  all_detected          1943.234279  1893.780442          NaN   \n",
       "            missing_or_extracted  2009.875878  1960.830164  1550.431395   \n",
       "pro         all_detected          1907.113823  1897.033699          NaN   \n",
       "            missing_or_extracted  2030.177174  1936.812662  1714.977095   \n",
       "regrettable all_detected          1913.685486  1875.341052  1688.800034   \n",
       "            missing_or_extracted  1961.329248  1898.286401  1729.345967   \n",
       "\n",
       "arch_discrepancy_severity           very_high  \n",
       "label       all_tooth_exist                    \n",
       "basic       all_detected                  NaN  \n",
       "            missing_or_extracted          NaN  \n",
       "invisalign  all_detected                  NaN  \n",
       "            missing_or_extracted          NaN  \n",
       "pro         all_detected                  NaN  \n",
       "            missing_or_extracted          NaN  \n",
       "regrettable all_detected                  NaN  \n",
       "            missing_or_extracted  1286.472635  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3: Pivot table transformation\n",
    "pivot_result = pd.pivot_table(\n",
    "    df,\n",
    "    values='simulated_arch_length',\n",
    "    index=['label', 'all_tooth_exist'],\n",
    "    columns='arch_discrepancy_severity'\n",
    ")\n",
    "\n",
    "pivot_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8026587d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invisalign</td>\n",
       "      <td>detected_arch_length</td>\n",
       "      <td>1971.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>basic</td>\n",
       "      <td>detected_arch_length</td>\n",
       "      <td>2083.646892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pro</td>\n",
       "      <td>detected_arch_length</td>\n",
       "      <td>1816.608868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic</td>\n",
       "      <td>detected_arch_length</td>\n",
       "      <td>1885.302329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basic</td>\n",
       "      <td>detected_arch_length</td>\n",
       "      <td>1971.601911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9853</th>\n",
       "      <td>basic</td>\n",
       "      <td>simulated_arch_length</td>\n",
       "      <td>1969.037121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9854</th>\n",
       "      <td>basic</td>\n",
       "      <td>simulated_arch_length</td>\n",
       "      <td>1853.592013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9855</th>\n",
       "      <td>basic</td>\n",
       "      <td>simulated_arch_length</td>\n",
       "      <td>1851.329048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>basic</td>\n",
       "      <td>simulated_arch_length</td>\n",
       "      <td>1715.296808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>basic</td>\n",
       "      <td>simulated_arch_length</td>\n",
       "      <td>1958.795191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label               variable        value\n",
       "0     invisalign   detected_arch_length  1971.032470\n",
       "1          basic   detected_arch_length  2083.646892\n",
       "2            pro   detected_arch_length  1816.608868\n",
       "3          basic   detected_arch_length  1885.302329\n",
       "4          basic   detected_arch_length  1971.601911\n",
       "...          ...                    ...          ...\n",
       "9853       basic  simulated_arch_length  1969.037121\n",
       "9854       basic  simulated_arch_length  1853.592013\n",
       "9855       basic  simulated_arch_length  1851.329048\n",
       "9856       basic  simulated_arch_length  1715.296808\n",
       "9857       basic  simulated_arch_length  1958.795191\n",
       "\n",
       "[9858 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 4: Wide to long format\n",
    "df_long = pd.melt(\n",
    "    df,\n",
    "    id_vars=['label'],\n",
    "    value_vars=['detected_arch_length', 'simulated_arch_length'],\n",
    ")\n",
    "\n",
    "df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b8d16-426d-42f9-997e-2737c28b596c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dfdbb8-69aa-4619-a565-440430de9619",
   "metadata": {},
   "source": [
    "## Part 2: Inferential Statistics\n",
    "Choose appropriate statistical tests based on your research questions and data types. Some common tests include:\n",
    "\n",
    ">**Note**: Below are some models we covered in previous statistics courses. You don’t need to use all of them — just pick the ones that fit your data and help answer your research questions. If you’d like to practice, you can try all of them. If your data or research questions are not suitable for all these models, you can skip this section and focus solely on completing Part 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3fa94d-44a4-4195-8e00-f5fcabbad72d",
   "metadata": {},
   "source": [
    "1. **Correlation Analysis**\n",
    "\n",
    "- For continuous variables\n",
    "- Calculate correlation coefficients\n",
    "- Test for statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db96ce31-c2e3-45ad-895c-b2b232a87fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detected_arch_length</th>\n",
       "      <th>simulated_arch_length</th>\n",
       "      <th>arch_length_discrepancy</th>\n",
       "      <th>num_incisors</th>\n",
       "      <th>num_canines</th>\n",
       "      <th>num_premolars</th>\n",
       "      <th>num_molars</th>\n",
       "      <th>avg_confidence_incisor</th>\n",
       "      <th>avg_confidence_canine</th>\n",
       "      <th>avg_confidence_premolar</th>\n",
       "      <th>avg_confidence_molar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>detected_arch_length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789175</td>\n",
       "      <td>0.406266</td>\n",
       "      <td>0.116979</td>\n",
       "      <td>0.052578</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>0.558208</td>\n",
       "      <td>-0.118154</td>\n",
       "      <td>-0.041614</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>-0.198164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulated_arch_length</th>\n",
       "      <td>0.789175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240584</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>-0.009482</td>\n",
       "      <td>0.113416</td>\n",
       "      <td>0.443147</td>\n",
       "      <td>-0.029606</td>\n",
       "      <td>0.016957</td>\n",
       "      <td>0.095490</td>\n",
       "      <td>-0.145720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arch_length_discrepancy</th>\n",
       "      <td>0.406266</td>\n",
       "      <td>-0.240584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091384</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>0.222879</td>\n",
       "      <td>-0.142683</td>\n",
       "      <td>-0.090995</td>\n",
       "      <td>-0.111199</td>\n",
       "      <td>-0.096377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_incisors</th>\n",
       "      <td>0.116979</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.091384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053706</td>\n",
       "      <td>-0.041570</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>-0.591000</td>\n",
       "      <td>-0.153589</td>\n",
       "      <td>-0.022295</td>\n",
       "      <td>-0.089574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_canines</th>\n",
       "      <td>0.052578</td>\n",
       "      <td>-0.009482</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.053706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011669</td>\n",
       "      <td>-0.003359</td>\n",
       "      <td>-0.099897</td>\n",
       "      <td>0.049661</td>\n",
       "      <td>-0.029708</td>\n",
       "      <td>-0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_premolars</th>\n",
       "      <td>0.133022</td>\n",
       "      <td>0.113416</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>-0.041570</td>\n",
       "      <td>-0.011669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005849</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>-0.011493</td>\n",
       "      <td>0.066190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_molars</th>\n",
       "      <td>0.558208</td>\n",
       "      <td>0.443147</td>\n",
       "      <td>0.222879</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>-0.003359</td>\n",
       "      <td>-0.005849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>-0.015992</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>-0.245393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_confidence_incisor</th>\n",
       "      <td>-0.118154</td>\n",
       "      <td>-0.029606</td>\n",
       "      <td>-0.142683</td>\n",
       "      <td>-0.591000</td>\n",
       "      <td>-0.099897</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>-0.042276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216836</td>\n",
       "      <td>0.064242</td>\n",
       "      <td>0.115937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_confidence_canine</th>\n",
       "      <td>-0.041614</td>\n",
       "      <td>0.016957</td>\n",
       "      <td>-0.090995</td>\n",
       "      <td>-0.153589</td>\n",
       "      <td>0.049661</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>-0.015992</td>\n",
       "      <td>0.216836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191332</td>\n",
       "      <td>0.023156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_confidence_premolar</th>\n",
       "      <td>0.019533</td>\n",
       "      <td>0.095490</td>\n",
       "      <td>-0.111199</td>\n",
       "      <td>-0.022295</td>\n",
       "      <td>-0.029708</td>\n",
       "      <td>-0.011493</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>0.064242</td>\n",
       "      <td>0.191332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_confidence_molar</th>\n",
       "      <td>-0.198164</td>\n",
       "      <td>-0.145720</td>\n",
       "      <td>-0.096377</td>\n",
       "      <td>-0.089574</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>0.066190</td>\n",
       "      <td>-0.245393</td>\n",
       "      <td>0.115937</td>\n",
       "      <td>0.023156</td>\n",
       "      <td>0.327301</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         detected_arch_length  simulated_arch_length  \\\n",
       "detected_arch_length                 1.000000               0.789175   \n",
       "simulated_arch_length                0.789175               1.000000   \n",
       "arch_length_discrepancy              0.406266              -0.240584   \n",
       "num_incisors                         0.116979               0.062838   \n",
       "num_canines                          0.052578              -0.009482   \n",
       "num_premolars                        0.133022               0.113416   \n",
       "num_molars                           0.558208               0.443147   \n",
       "avg_confidence_incisor              -0.118154              -0.029606   \n",
       "avg_confidence_canine               -0.041614               0.016957   \n",
       "avg_confidence_premolar              0.019533               0.095490   \n",
       "avg_confidence_molar                -0.198164              -0.145720   \n",
       "\n",
       "                         arch_length_discrepancy  num_incisors  num_canines  \\\n",
       "detected_arch_length                    0.406266      0.116979     0.052578   \n",
       "simulated_arch_length                  -0.240584      0.062838    -0.009482   \n",
       "arch_length_discrepancy                 1.000000      0.091384     0.097200   \n",
       "num_incisors                            0.091384      1.000000     0.053706   \n",
       "num_canines                             0.097200      0.053706     1.000000   \n",
       "num_premolars                           0.041489     -0.041570    -0.011669   \n",
       "num_molars                              0.222879      0.036105    -0.003359   \n",
       "avg_confidence_incisor                 -0.142683     -0.591000    -0.099897   \n",
       "avg_confidence_canine                  -0.090995     -0.153589     0.049661   \n",
       "avg_confidence_premolar                -0.111199     -0.022295    -0.029708   \n",
       "avg_confidence_molar                   -0.096377     -0.089574    -0.000413   \n",
       "\n",
       "                         num_premolars  num_molars  avg_confidence_incisor  \\\n",
       "detected_arch_length          0.133022    0.558208               -0.118154   \n",
       "simulated_arch_length         0.113416    0.443147               -0.029606   \n",
       "arch_length_discrepancy       0.041489    0.222879               -0.142683   \n",
       "num_incisors                 -0.041570    0.036105               -0.591000   \n",
       "num_canines                  -0.011669   -0.003359               -0.099897   \n",
       "num_premolars                 1.000000   -0.005849                0.018750   \n",
       "num_molars                   -0.005849    1.000000               -0.042276   \n",
       "avg_confidence_incisor        0.018750   -0.042276                1.000000   \n",
       "avg_confidence_canine         0.006089   -0.015992                0.216836   \n",
       "avg_confidence_premolar      -0.011493    0.025455                0.064242   \n",
       "avg_confidence_molar          0.066190   -0.245393                0.115937   \n",
       "\n",
       "                         avg_confidence_canine  avg_confidence_premolar  \\\n",
       "detected_arch_length                 -0.041614                 0.019533   \n",
       "simulated_arch_length                 0.016957                 0.095490   \n",
       "arch_length_discrepancy              -0.090995                -0.111199   \n",
       "num_incisors                         -0.153589                -0.022295   \n",
       "num_canines                           0.049661                -0.029708   \n",
       "num_premolars                         0.006089                -0.011493   \n",
       "num_molars                           -0.015992                 0.025455   \n",
       "avg_confidence_incisor                0.216836                 0.064242   \n",
       "avg_confidence_canine                 1.000000                 0.191332   \n",
       "avg_confidence_premolar               0.191332                 1.000000   \n",
       "avg_confidence_molar                  0.023156                 0.327301   \n",
       "\n",
       "                         avg_confidence_molar  \n",
       "detected_arch_length                -0.198164  \n",
       "simulated_arch_length               -0.145720  \n",
       "arch_length_discrepancy             -0.096377  \n",
       "num_incisors                        -0.089574  \n",
       "num_canines                         -0.000413  \n",
       "num_premolars                        0.066190  \n",
       "num_molars                          -0.245393  \n",
       "avg_confidence_incisor               0.115937  \n",
       "avg_confidence_canine                0.023156  \n",
       "avg_confidence_premolar              0.327301  \n",
       "avg_confidence_molar                 1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric = df.select_dtypes(include='number')\n",
    "df_numeric.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de575837-6c2d-4f13-bdd6-a4b03861e9ea",
   "metadata": {},
   "source": [
    "2. **Group Comparisons**   \n",
    "    Choose appropriate tests based on your data:\n",
    "\n",
    "- T-tests (comparing two groups)\n",
    "   - Example: A t-test can help determine if the average salary of employees in two departments (e.g., Sales vs. Marketing) is significantly different.<br><br>\n",
    "- ANOVA (comparing multiple groups)\n",
    "   - Example: ANOVA can test whether average house prices vary significantly between different cities (e.g., City A, City B, City C).<br><br>\n",
    "- Optional: Non-parametric tests: used when assumptions of parametric tests are not met, such as the Mann-Whitney U test or Kruskal-Wallis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497c60d8-5e26-4074-bca1-e5cf5987ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test: Compare arch lengths between basic and pro cases\n",
      "TtestResult(statistic=np.float64(-0.565350489134896), pvalue=np.float64(0.5718688580157401), df=np.float64(3790.0))\n",
      "T-test: Compare arch lengths between basic and invisalign cases\n",
      "TtestResult(statistic=np.float64(-8.902384104924641), pvalue=np.float64(8.361599635662965e-19), df=np.float64(3734.0))\n",
      "T-test: Compare arch lengths between basic and regrettable cases\n",
      "TtestResult(statistic=np.float64(-8.902384104924641), pvalue=np.float64(8.361599635662965e-19), df=np.float64(3734.0))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# T-test: Compare arch lengths between basic and invisalign cases\n",
    "label_ttest_basic_pro = stats.ttest_ind(\n",
    "    df[df['label'] == 'basic']['arch_length_discrepancy'],\n",
    "    df[df['label'] == 'pro']['arch_length_discrepancy']\n",
    ")\n",
    "\n",
    "print(\"T-test: Compare arch lengths between basic and pro cases\")\n",
    "print(label_ttest_basic_pro)\n",
    "\n",
    "label_ttest_basic_invisalign = stats.ttest_ind(\n",
    "    df[df['label'] == 'basic']['arch_length_discrepancy'],\n",
    "    df[df['label'] == 'invisalign']['arch_length_discrepancy']\n",
    ")\n",
    "\n",
    "print(\"T-test: Compare arch lengths between basic and invisalign cases\")\n",
    "print(label_ttest_basic_invisalign)\n",
    "\n",
    "label_ttest_basic_regrettable = stats.ttest_ind(\n",
    "    df[df['label'] == 'basic']['arch_length_discrepancy'],\n",
    "    df[df['label'] == 'regrettable']['arch_length_discrepancy']\n",
    ")\n",
    "\n",
    "print(\"T-test: Compare arch lengths between basic and regrettable cases\")\n",
    "print(label_ttest_basic_invisalign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe8a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=np.float64(107.55344653758648), pvalue=np.float64(1.899824063528475e-67))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANOVA: Compare arch length discrepancies across different labels\n",
    "labels = ['basic', 'pro', 'invisalign', 'regrettable']\n",
    "discrepancies_by_label = [df[df['label'] == label]['arch_length_discrepancy'] for label in labels]\n",
    "label_anova = stats.f_oneway(*discrepancies_by_label)\n",
    "label_anova\n",
    "#F_onewayResult(statistic=np.float64(107.55344653758648), pvalue=np.float64(1.899824063528475e-67))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b74c3-daf5-4186-83fb-87e4d66ced95",
   "metadata": {},
   "source": [
    "3. **Regression Analysis**\n",
    "\n",
    "- Simple Linear Regression: To examine the relationship between a continuous dependent variable and a single independent variable.\n",
    "   - Example: Predicting house prices (dependent variable) based on the size of the house (independent variable).<br><br>\n",
    "- Multiple Linear Regression: To examine the relationship between a continuous dependent variable and multiple independent variables.\n",
    "   - Example: Predicting house prices (dependent variable) based on multiple factors like the size of the house, number of bedrooms, and location (independent variables).<br><br>\n",
    "- Logistic Regression: If the dependent variable is binary (e.g., yes/no, success/failure), logistic regression can be used.\n",
    "   - Example: Predicting whether a customer will buy a product (binary dependent variable: yes/no) based on their age and income (independent variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "908be043-98f0-4e86-ae33-f4bcbcd9cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Linear Regression Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     199.6\n",
      "Date:                Tue, 03 Dec 2024   Prob (F-statistic):           1.91e-44\n",
      "Time:                        21:03:23   Log-Likelihood:                -7239.9\n",
      "No. Observations:                4929   AIC:                         1.448e+04\n",
      "Df Residuals:                    4927   BIC:                         1.450e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                       0.4432      0.024     18.185      0.000       0.395       0.491\n",
      "arch_length_discrepancy     0.0027      0.000     14.126      0.000       0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                      684.322   Durbin-Watson:                   1.905\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1003.285\n",
      "Skew:                           1.101   Prob(JB):                    1.38e-218\n",
      "Kurtosis:                       2.800   Cond. No.                         211.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Simple Linear Regression\n",
    "# Study relationship between house price (dependent) and square footage (independent)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare data\n",
    "X = df['arch_length_discrepancy'] \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "X = sm.add_constant(X)  # Add constant term\n",
    "\n",
    "# Fit model\n",
    "simple_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# View detailed results\n",
    "print(\"\\nSimple Linear Regression Results:\")\n",
    "print(simple_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e75292c7-d927-4f91-b377-cd10074674de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple Linear Regression Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.063\n",
      "Model:                            OLS   Adj. R-squared:                  0.061\n",
      "Method:                 Least Squares   F-statistic:                     30.05\n",
      "Date:                Tue, 03 Dec 2024   Prob (F-statistic):           4.76e-62\n",
      "Time:                        21:03:23   Log-Likelihood:                -7177.4\n",
      "No. Observations:                4929   AIC:                         1.438e+04\n",
      "Df Residuals:                    4917   BIC:                         1.446e+04\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      10.1185      1.742      5.807      0.000       6.703      13.534\n",
      "detected_arch_length    -4.756e+04   3.63e+04     -1.311      0.190   -1.19e+05    2.36e+04\n",
      "simulated_arch_length    4.756e+04   3.63e+04      1.311      0.190   -2.36e+04    1.19e+05\n",
      "arch_length_discrepancy  4.756e+04   3.63e+04      1.311      0.190   -2.36e+04    1.19e+05\n",
      "num_incisors               -0.1148      0.103     -1.110      0.267      -0.317       0.088\n",
      "num_canines                 0.0064      0.178      0.036      0.971      -0.343       0.355\n",
      "num_premolars               0.1258      0.040      3.107      0.002       0.046       0.205\n",
      "num_molars                 -0.0792      0.025     -3.195      0.001      -0.128      -0.031\n",
      "avg_confidence_incisor     -4.7618      1.360     -3.501      0.000      -7.428      -2.095\n",
      "avg_confidence_canine      -4.8655      0.590     -8.252      0.000      -6.021      -3.710\n",
      "avg_confidence_premolar     0.2625      0.846      0.310      0.756      -1.395       1.920\n",
      "avg_confidence_molar       -1.2328      0.755     -1.632      0.103      -2.714       0.248\n",
      "==============================================================================\n",
      "Omnibus:                      654.872   Durbin-Watson:                   1.911\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              947.323\n",
      "Skew:                           1.070   Prob(JB):                    1.96e-206\n",
      "Kurtosis:                       2.824   Cond. No.                     1.18e+10\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.18e+10. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Multiple Linear Regression\n",
    "X__numeric = df.select_dtypes(include='number')\n",
    "X_multi = sm.add_constant(X__numeric)\n",
    "y_multi = le.fit_transform(df['label'])\n",
    "\n",
    "multi_model = sm.OLS(y_multi, X_multi).fit()\n",
    "\n",
    "print(\"\\nMultiple Linear Regression Results:\")\n",
    "print(multi_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f43433-77a7-43ed-837e-20eceb56ee46",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6aa55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.009534\n",
      "         Iterations: 35\n",
      "\n",
      "Multinomial Logistic Regression Results:\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                 4929\n",
      "Model:                        MNLogit   Df Residuals:                     4905\n",
      "Method:                           MLE   Df Model:                           21\n",
      "Date:                Tue, 03 Dec 2024   Pseudo R-squ.:                 0.03300\n",
      "Time:                        21:03:24   Log-Likelihood:                -4976.0\n",
      "converged:                      False   LL-Null:                       -5145.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.543e-59\n",
      "===========================================================================================\n",
      "       label=invisalign       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -3.8416      1.716     -2.238      0.025      -7.206      -0.478\n",
      "arch_length_discrepancy  -271.0285   3266.542     -0.083      0.934   -6673.333    6131.276\n",
      "simulated_arch_length    -271.0330   3266.542     -0.083      0.934   -6673.337    6131.271\n",
      "detected_arch_length      271.0350   3266.477      0.083      0.934   -6131.143    6673.213\n",
      "num_incisors               -0.0927      0.258     -0.359      0.720      -0.599       0.414\n",
      "num_canines                -1.0612      0.505     -2.102      0.036      -2.051      -0.072\n",
      "num_premolars               0.3062      0.149      2.053      0.040       0.014       0.599\n",
      "num_molars                 -0.2319      0.076     -3.038      0.002      -0.381      -0.082\n",
      "-------------------------------------------------------------------------------------------\n",
      "              label=pro       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -3.8187      1.764     -2.165      0.030      -7.275      -0.362\n",
      "arch_length_discrepancy  -128.5271        nan        nan        nan         nan         nan\n",
      "simulated_arch_length    -128.5273        nan        nan        nan         nan         nan\n",
      "detected_arch_length      128.5271        nan        nan        nan         nan         nan\n",
      "num_incisors                0.1885      0.268      0.704      0.481      -0.336       0.713\n",
      "num_canines                -0.3546      0.562     -0.632      0.528      -1.455       0.746\n",
      "num_premolars               0.5673      0.149      3.807      0.000       0.275       0.859\n",
      "num_molars                  0.0469      0.074      0.638      0.524      -0.097       0.191\n",
      "-------------------------------------------------------------------------------------------\n",
      "      label=regrettable       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -4.1952      1.585     -2.646      0.008      -7.303      -1.088\n",
      "arch_length_discrepancy   -71.8902    822.085     -0.087      0.930   -1683.147    1539.366\n",
      "simulated_arch_length     -71.8988    822.085     -0.087      0.930   -1683.155    1539.358\n",
      "detected_arch_length       71.8990    822.085      0.087      0.930   -1539.358    1683.156\n",
      "num_incisors                0.5579      0.235      2.374      0.018       0.097       1.019\n",
      "num_canines                -0.0934      0.503     -0.186      0.853      -1.079       0.892\n",
      "num_premolars               0.1380      0.135      1.019      0.308      -0.127       0.403\n",
      "num_molars                 -0.3484      0.079     -4.411      0.000      -0.503      -0.194\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nkohei/anaconda3/envs/McDaniel/lib/python3.13/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/nkohei/anaconda3/envs/McDaniel/lib/python3.13/site-packages/statsmodels/discrete/discrete_model.py:5475: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse = np.sqrt(np.diag(self.cov_params()))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 3: Logistic Regression\n",
    "# Predict binary outcome (e.g., whether customer will buy a product)\n",
    "#build for basic prediction model\n",
    "from statsmodels.formula.api import logit\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "\n",
    "df['label'] = df['label'].astype('category')\n",
    "\n",
    "X = df[['arch_length_discrepancy', 'simulated_arch_length', 'detected_arch_length', \n",
    "        'num_incisors', 'num_canines', 'num_premolars', 'num_molars']]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = df['label']\n",
    "\n",
    "mnlogit_model = sm.MNLogit(y, X).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(\"\\nMultinomial Logistic Regression Results:\")\n",
    "print(mnlogit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3444d6-0546-4e48-9b1b-d5b81bb99896",
   "metadata": {},
   "source": [
    "## Optional: Part 3: Advanced Models \n",
    "Some advanced models, such as machine learning models (e.g., Random Forest, Support Vector Machine) and time series analysis models, will be covered in future courses. If you are already familiar with these techniques and wish to practice, feel free to explore them. However, this is not required for the current assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569fb3c7-3399-4b13-a4e5-812ad0ebccf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_validate, KFold\n\u001b[0;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124march_length_discrepancy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_incisors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_canines\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_premolars\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_molars\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvisalign\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      9\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Example 4: Random Forest with Cross Validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "X = df[['arch_length_discrepancy', 'num_incisors', 'num_canines', 'num_premolars', 'num_molars']]\n",
    "y = (df['label'] == 'invisalign').astype(int)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(rf_model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "print(\"Cross Validation Results:\")\n",
    "print(f\"Accuracy: {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std() * 2:.4f})\")\n",
    "print(f\"Precision: {cv_results['test_precision'].mean():.4f} (+/- {cv_results['test_precision'].std() * 2:.4f})\")\n",
    "print(f\"Recall: {cv_results['test_recall'].mean():.4f} (+/- {cv_results['test_recall'].std() * 2:.4f})\")\n",
    "print(f\"F1 Score: {cv_results['test_f1'].mean():.4f} (+/- {cv_results['test_f1'].std() * 2:.4f})\")\n",
    "\n",
    "rf_model.fit(X, y)\n",
    "feature_importance = pd.DataFrame(rf_model.feature_importances_, \n",
    "                            index=X.columns, \n",
    "                            columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548699d-faaf-4789-8096-56defeb19e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addc0427-8f5d-4665-901b-0ce53f191e23",
   "metadata": {},
   "source": [
    "## <font color=\"Purple\"> Part 4: Documentation </font>\n",
    "\n",
    "Provide a clear and concise summary of your data analysis, including the interpretation of the results. This should explain the key insights gained from the analyses and their relevance to your research questions.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Write at least one paragraph summarizing your findings from the data analysis.\n",
    "- Highlight significant results and their interpretations.\n",
    "- Optional: Discuss any limitations or challenges encountered during the analysis.\n",
    "  \n",
    "Example Structure:\n",
    "\n",
    "- What you found: Summarize key results (e.g., correlations, group differences, or significant relationships).\n",
    "- Why it matters: Explain how these findings address your research questions or contribute to your understanding of the data.\n",
    "- Optional: What’s next: suggest any follow-up steps or analyses based on your findings.\n",
    "  \n",
    "Don’t forget to complete the documentation, as it helps consolidate your work and ensures clear communication of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53672f08-ea02-433e-8441-65281b807385",
   "metadata": {},
   "source": [
    "# Summary Findings\n",
    "\n",
    "## Dataset Overview\n",
    "The dataset was found to be imbalanced, with the dominant label, \"Basic,\" accounting for 63% of total observations. This category corresponds to treatments primarily addressing front-tooth corrections, which are typically less complex and the most cost-effective. The remaining observations were distributed almost equally across the other categories. Recognizing this imbalance, we prioritized insights that align with industrial standards and focused on arch length discrepancy, a critical feature representing the difference between the ideal and actual dental arch lengths.\n",
    "\n",
    "## Statistical Insights\n",
    "To examine the relationship between treatment plans and arch length discrepancy, we conducted statistical tests:\n",
    "\n",
    "- ANOVA: Results (p=1.90e-67) confirmed highly significant differences between treatment groups, underscoring the importance of arch length discrepancy in categorizing treatments.\n",
    "- T-tests: Pairwise comparisons revealed: No statistically significant difference between the \"Basic\" and \"Pro\" treatment plans (p=0.572), indicating similarities in detected and simulated arch lengths.\n",
    "Significant differences between \"Basic\" and other treatment categories (\"Invisalign\" and \"Regrettable\"), demonstrating the utility of arch length discrepancy as a distinguishing feature in these cases.\n",
    "These findings suggest that while \"Pro\" treatment involves molars and premolars (likely for chewing or functional issues), patients may prioritize cost-effective options like \"Basic\" treatments, influenced by affordability or other factors.\n",
    "\n",
    "## Model Development and Evaluation\n",
    "Given the multi-category nature of the target variable, we framed the problem as a multi-class classification task. Initial modeling efforts included:\n",
    "\n",
    "OLS Regression and Logistic Regression: Despite extensive exploration of numerical variables, these models showed limited explainability, as indicated by low R-squared values.\n",
    "Random Forest Classifier: Recognizing the limitations of linear approaches, we implemented a Random Forest model, which demonstrated significantly stronger predictive performance:\n",
    "- Accuracy: ~0.89\n",
    "- Precision: ~0.88\n",
    "- Recall: ~0.87\n",
    "- F1 Score: ~0.88\n",
    "These metrics highlight the model’s robustness and its ability to handle the dataset’s inherent class imbalance. However, the imbalanced nature of the data necessitates cautious interpretation of these metrics, particularly for minority classes.\n",
    "\n",
    "## Key Takeaways\n",
    "Arch Length Discrepancy: A pivotal feature for distinguishing between treatment categories, particularly \"Basic\" vs. \"Invisalign\" or \"Regrettable.\"\n",
    "Linear vs. Non-Linear Models: While linear models failed to capture the complexity of the problem, Random Forest emerged as a powerful alternative, suggesting non-linear relationships in the data.\n",
    "Practical Implications: Patients may opt for cost-effective \"Basic\" treatments over \"Pro\" due to financial considerations or personal preferences, even when discrepancies are apparent.\n",
    "## Next Steps\n",
    "Class Imbalance Handling: Apply techniques such as oversampling, undersampling, or cost-sensitive learning to improve performance on minority classes.\n",
    "Explainability and Deployment: Investigate interpretability tools (e.g., SHAP values) to understand feature importance, which could support clinical decision-making and enhance patient communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee78a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "McDaniel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
